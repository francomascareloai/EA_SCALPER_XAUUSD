# =============================================================================
# CONFIGURAÇÃO DE AMBIENTE - MCP + LITELLM
# =============================================================================
# Copie este arquivo para .env e preencha com seus valores

# -----------------------------------------------------------------------------
# GitHub MCP Configuration
# -----------------------------------------------------------------------------
GITHUB_PERSONAL_ACCESS_TOKEN=your_github_token_here

# -----------------------------------------------------------------------------
# Configurações do Projeto
# -----------------------------------------------------------------------------
PROJECT_ROOT=c:\Users\Admin\Documents\EA_SCALPER_XAUUSD
VIRTUAL_ENV=c:\Users\Admin\Documents\EA_SCALPER_XAUUSD\.venv

# Outros MCPs podem usar estas variáveis
# API_KEY=your_api_key_here
# DATABASE_URL=sqlite:///data/tasks.db

# =============================================================================
# LITELLM + OPENROUTER CONFIGURATION
# =============================================================================

# -----------------------------------------------------------------------------
# OpenRouter API (OBRIGATÓRIO para LiteLLM)
# -----------------------------------------------------------------------------
# Sua chave de API do OpenRouter - Obtenha gratuitamente em: https://openrouter.ai/
OPENROUTER_API_KEY=your_openrouter_api_key_here

# URL base da API do OpenRouter
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# Site URL para referência (usado nos headers)
OPENROUTER_SITE_URL=http://localhost:3000

# Nome da sua aplicação
OPENROUTER_APP_NAME=LiteLLM Cache Local

# -----------------------------------------------------------------------------
# Cache Configuration
# -----------------------------------------------------------------------------
# Diretório para cache local
CACHE_DIR=./cache/litellm_cache

# Tempo de vida do cache em segundos (3600 = 1 hora)
CACHE_TTL=3600

# Tamanho máximo do cache em GB
CACHE_MAX_SIZE_GB=5

# Tipo de cache (disk, redis, memory)
CACHE_TYPE=disk

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
# Nível de log (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Arquivo de log
LOG_FILE=./logs/litellm.log

# -----------------------------------------------------------------------------
# Model Preferences
# -----------------------------------------------------------------------------
# Modelo padrão a usar
DEFAULT_MODEL=gpt-3.5-turbo-free

# Modelos de fallback (separados por vírgula)
FALLBACK_MODELS=llama-3.1-8b-free,mixtral-8x7b-free,gemma-7b-free

# Preferir modelos gratuitos
PREFER_FREE_MODELS=true

# -----------------------------------------------------------------------------
# Rate Limiting
# -----------------------------------------------------------------------------
# Requests por minuto
RATE_LIMIT_RPM=60

# Tokens por minuto
RATE_LIMIT_TPM=100000

# -----------------------------------------------------------------------------
# Timeout Configuration
# -----------------------------------------------------------------------------
# Timeout para requests em segundos
REQUEST_TIMEOUT=30

# Timeout para leitura em segundos
READ_TIMEOUT=60

# -----------------------------------------------------------------------------
# Performance Monitoring
# -----------------------------------------------------------------------------
# Habilitar monitoramento de métricas
ENABLE_MONITORING=true

# Arquivo para exportar métricas
METRICS_FILE=./logs/metrics.json

# -----------------------------------------------------------------------------
# Security Settings
# -----------------------------------------------------------------------------
# Não logar dados sensíveis
LOG_SENSITIVE_DATA=false

# Sanitizar logs
SANITIZE_LOGS=true

# Validar entrada
VALIDATE_INPUT=true

# =============================================================================
# INSTRUÇÕES DE CONFIGURAÇÃO
# =============================================================================
# 
# PARA MCP:
# 1. Crie um Personal Access Token no GitHub:
#    https://github.com/settings/tokens
# 2. Substitua 'your_github_token_here' pelo seu token real
#
# PARA LITELLM:
# 1. Crie uma conta gratuita no OpenRouter:
#    https://openrouter.ai/
# 2. Obtenha sua API key gratuita
# 3. Substitua 'your_openrouter_api_key_here' pela sua chave
#
# FINALIZAÇÃO:
# 1. Copie este arquivo para .env
# 2. Preencha os valores necessários
# 3. Reinicie o Trae para aplicar as configurações
# 4. Execute: pip install -r requirements.txt
# 5. Teste com: python litellm_cache_example.py
# =============================================================================