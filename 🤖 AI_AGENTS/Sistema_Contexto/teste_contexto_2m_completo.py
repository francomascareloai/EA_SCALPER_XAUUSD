#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Teste Completo do Sistema de Contexto Expandido - 2M Tokens

Este script demonstra o funcionamento completo do sistema,
adicionando mÃºltiplos documentos e testando todas as funcionalidades.
"""

import os
import time
from sistema_contexto_expandido_2m import ContextManager

def criar_documentos_trading():
    """Cria mÃºltiplos documentos sobre trading para testar o sistema."""
    documentos = {
        "smc_concepts": """
        Smart Money Concepts (SMC) - Conceitos Fundamentais
        
        Order Blocks sÃ£o zonas de liquidez onde instituiÃ§Ãµes colocaram grandes ordens.
        Estes blocos representam Ã¡reas de interesse para smart money e frequentemente
        atuam como suporte ou resistÃªncia.
        
        Fair Value Gaps (FVG) sÃ£o lacunas no preÃ§o que indicam desequilÃ­brio entre
        oferta e demanda. O mercado tende a retornar para preencher essas lacunas.
        
        Liquidity Sweeps ocorrem quando o preÃ§o move rapidamente para capturar
        liquidez de stops de traders retail antes de reverter na direÃ§Ã£o oposta.
        
        Market Structure Ã© fundamental para entender a direÃ§Ã£o do mercado.
        Higher Highs e Higher Lows indicam tendÃªncia de alta, enquanto
        Lower Highs e Lower Lows indicam tendÃªncia de baixa.
        
        Break of Structure (BOS) confirma mudanÃ§a na direÃ§Ã£o do mercado,
        enquanto Change of Character (CHoCH) indica possÃ­vel reversÃ£o.
        """ * 100,  # Repetir para aumentar o tamanho
        
        "risk_management": """
        GestÃ£o de Risco em Trading AlgorÃ­tmico
        
        O gerenciamento de risco Ã© o aspecto mais crÃ­tico do trading.
        Sem uma gestÃ£o adequada, mesmo a melhor estratÃ©gia pode levar Ã  ruÃ­na.
        
        Regra dos 2%: Nunca arrisque mais de 2% do capital em uma Ãºnica operaÃ§Ã£o.
        Esta regra protege contra perdas catastrÃ³ficas e permite recuperaÃ§Ã£o.
        
        Position Sizing deve ser calculado com base no stop loss e no risco aceitÃ¡vel.
        Tamanho da posiÃ§Ã£o = (Capital * % Risco) / (PreÃ§o de entrada - Stop loss)
        
        Drawdown mÃ¡ximo aceitÃ¡vel deve ser definido previamente.
        Recomenda-se nÃ£o exceder 20% de drawdown em contas reais.
        
        DiversificaÃ§Ã£o entre diferentes pares e estratÃ©gias reduz o risco.
        CorrelaÃ§Ã£o entre ativos deve ser considerada para evitar exposiÃ§Ã£o excessiva.
        
        Risk-Reward ratio mÃ­nimo de 1:2 garante lucratividade mesmo com 50% de acerto.
        OperaÃ§Ãµes com ratio inferior devem ser evitadas.
        """ * 150,
        
        "algorithmic_strategies": """
        EstratÃ©gias de Trading AlgorÃ­tmico AvanÃ§adas
        
        Scalping Algorithms focam em pequenos movimentos de preÃ§o em timeframes baixos.
        Requerem execuÃ§Ã£o rÃ¡pida e spreads baixos para serem lucrativos.
        
        Mean Reversion strategies assumem que preÃ§os retornam Ã  mÃ©dia.
        Bollinger Bands e RSI sÃ£o indicadores comuns nesta abordagem.
        
        Trend Following algorithms identificam e seguem tendÃªncias estabelecidas.
        Moving averages e breakouts sÃ£o sinais tÃ­picos desta estratÃ©gia.
        
        Arbitrage opportunities exploram diferenÃ§as de preÃ§o entre mercados.
        Requer tecnologia avanÃ§ada e conexÃµes rÃ¡pidas para ser efetivo.
        
        Machine Learning models podem identificar padrÃµes complexos nos dados.
        Random Forest, SVM e Neural Networks sÃ£o algoritmos populares.
        
        High Frequency Trading (HFT) opera em microssegundos.
        Requer infraestrutura especializada e proximidade aos servidores.
        
        Market Making strategies fornecem liquidez e lucram com o spread.
        Requer gestÃ£o cuidadosa do inventÃ¡rio e risco de direÃ§Ã£o.
        """ * 200,
        
        "technical_analysis": """
        AnÃ¡lise TÃ©cnica para Trading Automatizado
        
        Candlestick Patterns fornecem insights sobre psicologia do mercado.
        Doji, Hammer, Engulfing sÃ£o padrÃµes de reversÃ£o importantes.
        
        Support and Resistance levels sÃ£o zonas crÃ­ticas de decisÃ£o.
        MÃºltiplos toques aumentam a importÃ¢ncia destes nÃ­veis.
        
        Volume Analysis confirma movimentos de preÃ§o.
        Volume crescente em breakouts indica forÃ§a do movimento.
        
        Fibonacci Retracements identificam nÃ­veis de correÃ§Ã£o provÃ¡veis.
        38.2%, 50% e 61.8% sÃ£o nÃ­veis de retraÃ§Ã£o mais significativos.
        
        Moving Averages suavizam dados de preÃ§o e identificam tendÃªncias.
        EMA reage mais rapidamente que SMA a mudanÃ§as de preÃ§o.
        
        Oscillators como RSI e Stochastic identificam condiÃ§Ãµes de sobrecompra/sobrevenda.
        DivergÃªncias entre preÃ§o e oscilador indicam possÃ­vel reversÃ£o.
        
        MACD combina tendÃªncia e momentum em um indicador.
        Crossovers e divergÃªncias sÃ£o sinais de entrada/saÃ­da.
        """ * 180
    }
    
    return documentos

def teste_completo_contexto_2m():
    """Executa teste completo do sistema de contexto expandido."""
    print("ğŸš€ TESTE COMPLETO - Sistema de Contexto Expandido 2M Tokens")
    print("=" * 80)
    
    # Inicializar sistema
    print("\nğŸ“Š Inicializando ContextManager...")
    cm = ContextManager(
        base_url="http://localhost:4000",
        model_name="deepseek-r1-free",
        cache_dir="./cache_teste_2m"
    )
    
    # Criar documentos de teste
    print("\nğŸ“ Criando documentos de teste...")
    documentos = criar_documentos_trading()
    
    total_chars = 0
    total_tokens = 0
    
    # Adicionar documentos ao contexto
    print("\nğŸ”„ Adicionando documentos ao contexto...")
    for nome, conteudo in documentos.items():
        print(f"   ğŸ“„ Processando: {nome}")
        
        # Adicionar ao contexto
        chunks = cm.add_context(conteudo, context_id=nome)
        
        chars = len(conteudo)
        tokens = cm._count_tokens(conteudo)
        total_chars += chars
        total_tokens += tokens
        
        print(f"      âœ“ {len(chunks)} chunks criados")
        print(f"      âœ“ {chars:,} caracteres, ~{tokens:,} tokens")
        
        time.sleep(0.5)  # Pequena pausa
    
    print(f"\nğŸ“Š Total processado: {total_chars:,} caracteres, ~{total_tokens:,} tokens")
    
    # Obter estatÃ­sticas
    print("\nğŸ“ˆ EstatÃ­sticas do sistema:")
    stats = cm.get_context_stats()
    
    for key, value in stats.items():
        if isinstance(value, list):
            print(f"   {key}: {len(value)} itens")
        elif isinstance(value, float):
            print(f"   {key}: {value:.2f}")
        else:
            print(f"   {key}: {value:,}" if isinstance(value, int) else f"   {key}: {value}")
    
    # Teste de busca semÃ¢ntica
    print("\nğŸ” Teste de busca semÃ¢ntica:")
    queries = [
        "Como funciona order block em SMC?",
        "Qual a regra dos 2% em gestÃ£o de risco?",
        "O que sÃ£o Fair Value Gaps?",
        "Como calcular position sizing?",
        "EstratÃ©gias de scalping algorÃ­tmico"
    ]
    
    for query in queries:
        print(f"\n   ğŸ” Query: {query}")
        relevant_chunks = cm.search_relevant_context(query, max_chunks=3)
        print(f"      âœ“ {len(relevant_chunks)} chunks relevantes encontrados")
        
        for i, chunk in enumerate(relevant_chunks):
            preview = chunk.content[:100].replace('\n', ' ').strip()
            print(f"      Chunk {i+1}: {preview}...")
            print(f"      ImportÃ¢ncia: {chunk.importance_score:.3f}, Tokens: {chunk.token_count}")
    
    # Teste de contexto expandido
    print("\nğŸ¯ Teste de contexto expandido:")
    test_queries = [
        "estratÃ©gias de trading",
        "gestÃ£o de risco",
        "anÃ¡lise tÃ©cnica"
    ]
    
    for query in test_queries:
        expanded_context = cm.build_expanded_context(query)
        expanded_tokens = cm._count_tokens(expanded_context)
        
        print(f"   Query: '{query}'")
        print(f"   âœ“ Contexto expandido: {expanded_tokens:,} tokens")
        print(f"   âœ“ Fator de expansÃ£o: {expanded_tokens / 163000:.2f}x do limite base")
    
    # Demonstrar capacidade de 2M tokens
    print("\nğŸš€ DemonstraÃ§Ã£o de capacidade 2M tokens:")
    
    # Simular adiÃ§Ã£o de mais conteÃºdo
    for i in range(5):
        large_content = "\n".join([
            f"Documento adicional {i+1} sobre trading algorÃ­tmico.",
            "Este conteÃºdo simula documentaÃ§Ã£o extensa sobre:",
            "- EstratÃ©gias avanÃ§adas de trading",
            "- AnÃ¡lise quantitativa de mercados",
            "- OtimizaÃ§Ã£o de algoritmos",
            "- Backtesting e validaÃ§Ã£o",
            "- GestÃ£o de portfÃ³lio",
            "- AnÃ¡lise de risco"
        ] * 1000)  # Repetir para criar conteÃºdo grande
        
        chunks = cm.add_context(large_content, context_id=f"doc_adicional_{i+1}")
        tokens = cm._count_tokens(large_content)
        
        print(f"   ğŸ“„ Documento {i+1}: {len(chunks)} chunks, ~{tokens:,} tokens")
    
    # EstatÃ­sticas finais
    print("\nğŸ“Š ESTATÃSTICAS FINAIS:")
    final_stats = cm.get_context_stats()
    
    print(f"   ğŸ’¾ Total de chunks: {final_stats['total_chunks']:,}")
    print(f"   ğŸ“ˆ Total de tokens: {final_stats['total_tokens']:,}")
    print(f"   ğŸš€ Fator de expansÃ£o: {final_stats['expansion_factor']:.1f}x")
    print(f"   ğŸ’¿ Tamanho do cache: {final_stats['cache_size_mb']:.2f} MB")
    print(f"   â­ ImportÃ¢ncia mÃ©dia: {final_stats['avg_importance_score']:.3f}")
    
    # Verificar se atingiu meta de 2M tokens
    if final_stats['total_tokens'] >= 2000000:
        print("\nğŸ‰ âœ… META ATINGIDA: Sistema processou 2M+ tokens com sucesso!")
    else:
        print(f"\nğŸ“ˆ Sistema processou {final_stats['total_tokens']:,} tokens")
        print(f"   Meta de 2M tokens: {(final_stats['total_tokens']/2000000)*100:.1f}% concluÃ­da")
    
    print("\n=== TESTE COMPLETO CONCLUÃDO ===")
    print("\nğŸ’¡ O sistema demonstrou capacidade de:")
    print("   âœ“ Processar grandes volumes de texto")
    print("   âœ“ Criar chunks inteligentes com embeddings")
    print("   âœ“ Realizar busca semÃ¢ntica eficiente")
    print("   âœ“ Expandir contexto alÃ©m do limite de 163k tokens")
    print("   âœ“ Manter cache persistente para performance")
    
    return final_stats

if __name__ == "__main__":
    try:
        stats = teste_completo_contexto_2m()
        print(f"\nğŸ† Teste concluÃ­do com {stats['total_tokens']:,} tokens processados!")
    except Exception as e:
        print(f"\nâŒ Erro durante o teste: {e}")
        import traceback
        traceback.print_exc()