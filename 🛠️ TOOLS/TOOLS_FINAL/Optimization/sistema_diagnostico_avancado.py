#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîç SISTEMA DE DIAGN√ìSTICO AVAN√áADO E CORRE√á√ÉO DE ERROS
Classificador Trading - An√°lise Profunda + Auto-Corre√ß√£o

Autor: ClassificadorTrading
Vers√£o: 6.0
Data: 13/08/2025

Recursos:
- Diagn√≥stico completo do sistema anterior
- Detec√ß√£o autom√°tica de problemas
- Corre√ß√£o de erros em tempo real
- An√°lise de logs detalhada
- Implementa√ß√£o de melhorias autom√°ticas
- Sistema de valida√ß√£o rigorosa
"""

import sys
import os
import json
import time
import logging
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import traceback
import psutil
import gc

# Configurar logging avan√ßado
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('diagnostico_avancado.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class SystemDiagnostics:
    """Sistema de Diagn√≥stico Avan√ßado"""
    
    def __init__(self):
        self.logger = logging.getLogger('SystemDiagnostics')
        self.issues_found = []
        self.performance_metrics = {}
        self.system_health = {}
    
    def run_full_diagnostic(self, base_path: str) -> Dict[str, Any]:
        """Executa diagn√≥stico completo do sistema"""
        self.logger.info("üîç INICIANDO DIAGN√ìSTICO COMPLETO DO SISTEMA")
        self.logger.info("=" * 70)
        
        base_path = Path(base_path)
        diagnostic_results = {
            'timestamp': datetime.now().isoformat(),
            'system_health': {},
            'file_analysis': {},
            'performance_analysis': {},
            'issues_detected': [],
            'recommendations': [],
            'auto_fixes_applied': []
        }
        
        # 1. An√°lise de sa√∫de do sistema
        self.logger.info("üìä 1. Analisando sa√∫de do sistema...")
        diagnostic_results['system_health'] = self._analyze_system_health()
        
        # 2. An√°lise de arquivos e estrutura
        self.logger.info("üìÅ 2. Analisando estrutura de arquivos...")
        diagnostic_results['file_analysis'] = self._analyze_file_structure(base_path)
        
        # 3. An√°lise de logs anteriores
        self.logger.info("üìã 3. Analisando logs de execu√ß√µes anteriores...")
        diagnostic_results['log_analysis'] = self._analyze_previous_logs(base_path)
        
        # 4. An√°lise de performance
        self.logger.info("‚ö° 4. Analisando performance do sistema...")
        diagnostic_results['performance_analysis'] = self._analyze_performance_issues()
        
        # 5. Detec√ß√£o de problemas espec√≠ficos
        self.logger.info("üîé 5. Detectando problemas espec√≠ficos...")
        diagnostic_results['issues_detected'] = self._detect_specific_issues(base_path)
        
        # 6. Gera√ß√£o de recomenda√ß√µes
        self.logger.info("üí° 6. Gerando recomenda√ß√µes...")
        diagnostic_results['recommendations'] = self._generate_recommendations()
        
        # 7. Aplica√ß√£o de corre√ß√µes autom√°ticas
        self.logger.info("üîß 7. Aplicando corre√ß√µes autom√°ticas...")
        diagnostic_results['auto_fixes_applied'] = self._apply_auto_fixes(base_path)
        
        self.logger.info("‚úÖ Diagn√≥stico completo finalizado")
        return diagnostic_results
    
    def _analyze_system_health(self) -> Dict[str, Any]:
        """Analisa sa√∫de geral do sistema"""
        try:
            # Informa√ß√µes de mem√≥ria
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('C:\\')
            cpu_percent = psutil.cpu_percent(interval=1)
            
            health = {
                'memory': {
                    'total_gb': round(memory.total / (1024**3), 2),
                    'available_gb': round(memory.available / (1024**3), 2),
                    'percent_used': memory.percent,
                    'status': 'OK' if memory.percent < 80 else 'WARNING' if memory.percent < 90 else 'CRITICAL'
                },
                'disk': {
                    'total_gb': round(disk.total / (1024**3), 2),
                    'free_gb': round(disk.free / (1024**3), 2),
                    'percent_used': round((disk.used / disk.total) * 100, 2),
                    'status': 'OK' if disk.free > 5*(1024**3) else 'WARNING'
                },
                'cpu': {
                    'percent_used': cpu_percent,
                    'status': 'OK' if cpu_percent < 70 else 'WARNING' if cpu_percent < 90 else 'CRITICAL'
                }
            }
            
            self.logger.info(f"üíæ Mem√≥ria: {health['memory']['percent_used']:.1f}% usada - {health['memory']['status']}")
            self.logger.info(f"üíø Disco: {health['disk']['percent_used']:.1f}% usado - {health['disk']['status']}")
            self.logger.info(f"üñ•Ô∏è CPU: {health['cpu']['percent_used']:.1f}% usado - {health['cpu']['status']}")
            
            return health
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na an√°lise de sa√∫de do sistema: {e}")
            return {'error': str(e)}
    
    def _analyze_file_structure(self, base_path: Path) -> Dict[str, Any]:
        """Analisa estrutura de arquivos"""
        analysis = {
            'total_mq4_files': 0,
            'organized_files': 0,
            'unorganized_files': 0,
            'metadata_files': 0,
            'report_files': 0,
            'structure_issues': []
        }
        
        try:
            # Contar arquivos MQ4 originais
            all_mq4_path = base_path / "CODIGO_FONTE_LIBRARY" / "MQL4_Source" / "All_MQ4"
            if all_mq4_path.exists():
                analysis['total_mq4_files'] = len(list(all_mq4_path.glob("*.mq4")))
                self.logger.info(f"üìÅ Arquivos MQ4 em All_MQ4: {analysis['total_mq4_files']}")
            
            # Contar arquivos organizados
            organized_paths = [
                base_path / "CODIGO_FONTE_LIBRARY" / "MQL4_Source" / "EAs",
                base_path / "CODIGO_FONTE_LIBRARY" / "MQL4_Source" / "Indicators",
                base_path / "CODIGO_FONTE_LIBRARY" / "MQL4_Source" / "Scripts"
            ]
            
            for path in organized_paths:
                if path.exists():
                    count = len(list(path.rglob("*.mq4")))
                    analysis['organized_files'] += count
                    self.logger.info(f"üìÇ Arquivos em {path.name}: {count}")
            
            # Contar metadados
            metadata_path = base_path / "CODIGO_FONTE_LIBRARY" / "MQL4_Source" / "Metadata"
            if metadata_path.exists():
                analysis['metadata_files'] = len(list(metadata_path.glob("*.json")))
                self.logger.info(f"üìÑ Arquivos de metadados: {analysis['metadata_files']}")
            
            # Contar relat√≥rios
            reports_path = base_path / "Reports"
            if reports_path.exists():
                analysis['report_files'] = len(list(reports_path.glob("*.md"))) + len(list(reports_path.glob("*.json")))
                self.logger.info(f"üìä Arquivos de relat√≥rio: {analysis['report_files']}")
            
            # Calcular arquivos n√£o organizados
            analysis['unorganized_files'] = analysis['total_mq4_files'] - analysis['organized_files']
            
            # Detectar problemas estruturais
            if analysis['unorganized_files'] > 0:
                analysis['structure_issues'].append(f"{analysis['unorganized_files']} arquivos ainda n√£o organizados")
            
            if analysis['metadata_files'] == 0:
                analysis['structure_issues'].append("Nenhum arquivo de metadados encontrado")
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na an√°lise de estrutura: {e}")
            return {'error': str(e)}
    
    def _analyze_previous_logs(self, base_path: Path) -> Dict[str, Any]:
        """Analisa logs de execu√ß√µes anteriores"""
        log_analysis = {
            'log_files_found': [],
            'errors_detected': [],
            'warnings_detected': [],
            'performance_issues': [],
            'success_patterns': []
        }
        
        try:
            # Procurar arquivos de log
            log_files = list(base_path.glob("*.log"))
            log_analysis['log_files_found'] = [str(f) for f in log_files]
            
            self.logger.info(f"üìã Arquivos de log encontrados: {len(log_files)}")
            
            for log_file in log_files:
                try:
                    with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # Detectar erros
                    error_patterns = [
                        r'ERROR.*',
                        r'Exception.*',
                        r'Traceback.*',
                        r'Failed.*',
                        r'‚ùå.*'
                    ]
                    
                    for pattern in error_patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        log_analysis['errors_detected'].extend(matches[:5])  # Primeiros 5
                    
                    # Detectar warnings
                    warning_patterns = [
                        r'WARNING.*',
                        r'‚ö†Ô∏è.*',
                        r'WARN.*'
                    ]
                    
                    for pattern in warning_patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        log_analysis['warnings_detected'].extend(matches[:5])
                    
                    # Detectar problemas de performance
                    if 'timeout' in content.lower() or 'slow' in content.lower():
                        log_analysis['performance_issues'].append(f"Problemas de performance em {log_file.name}")
                    
                    # Detectar padr√µes de sucesso
                    if 'conclu√≠do com sucesso' in content.lower():
                        log_analysis['success_patterns'].append(f"Execu√ß√£o bem-sucedida em {log_file.name}")
                
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Erro ao analisar {log_file}: {e}")
            
            self.logger.info(f"üîç Erros detectados: {len(log_analysis['errors_detected'])}")
            self.logger.info(f"‚ö†Ô∏è Warnings detectados: {len(log_analysis['warnings_detected'])}")
            
            return log_analysis
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na an√°lise de logs: {e}")
            return {'error': str(e)}
    
    def _analyze_performance_issues(self) -> Dict[str, Any]:
        """Analisa problemas de performance"""
        performance = {
            'memory_leaks_detected': False,
            'cpu_bottlenecks': False,
            'io_bottlenecks': False,
            'threading_issues': False,
            'recommendations': []
        }
        
        try:
            # Verificar uso de mem√≥ria
            memory = psutil.virtual_memory()
            if memory.percent > 85:
                performance['memory_leaks_detected'] = True
                performance['recommendations'].append("Implementar garbage collection mais agressivo")
            
            # Verificar CPU
            cpu_percent = psutil.cpu_percent(interval=1)
            if cpu_percent > 80:
                performance['cpu_bottlenecks'] = True
                performance['recommendations'].append("Otimizar algoritmos de processamento")
            
            # Verificar I/O
            disk_io = psutil.disk_io_counters()
            if disk_io and disk_io.read_time > 1000:  # ms
                performance['io_bottlenecks'] = True
                performance['recommendations'].append("Implementar cache de arquivos")
            
            return performance
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na an√°lise de performance: {e}")
            return {'error': str(e)}
    
    def _detect_specific_issues(self, base_path: Path) -> List[Dict[str, Any]]:
        """Detecta problemas espec√≠ficos do sistema"""
        issues = []
        
        try:
            # Issue 1: Arquivos n√£o processados
            all_mq4_path = base_path / "CODIGO_FONTE_LIBRARY" / "MQL4_Source" / "All_MQ4"
            if all_mq4_path.exists():
                unprocessed_count = len(list(all_mq4_path.glob("*.mq4")))
                if unprocessed_count > 0:
                    issues.append({
                        'type': 'unprocessed_files',
                        'severity': 'HIGH',
                        'description': f"{unprocessed_count} arquivos MQ4 n√£o foram processados",
                        'solution': "Executar processamento completo com valida√ß√£o"
                    })
            
            # Issue 2: Metadados incompletos
            metadata_path = base_path / "CODIGO_FONTE_LIBRARY" / "MQL4_Source" / "Metadata"
            if not metadata_path.exists() or len(list(metadata_path.glob("*.json"))) == 0:
                issues.append({
                    'type': 'missing_metadata',
                    'severity': 'MEDIUM',
                    'description': "Metadados n√£o foram gerados ou est√£o incompletos",
                    'solution': "Regenerar metadados com sistema aprimorado"
                })
            
            # Issue 3: Estrutura de pastas incompleta
            required_dirs = [
                "CODIGO_FONTE_LIBRARY/MQL4_Source/EAs",
                "CODIGO_FONTE_LIBRARY/MQL4_Source/Indicators",
                "CODIGO_FONTE_LIBRARY/MQL4_Source/Scripts",
                "Reports",
                "Metadata"
            ]
            
            for dir_path in required_dirs:
                full_path = base_path / dir_path
                if not full_path.exists():
                    issues.append({
                        'type': 'missing_directory',
                        'severity': 'MEDIUM',
                        'description': f"Diret√≥rio obrigat√≥rio n√£o existe: {dir_path}",
                        'solution': f"Criar diret√≥rio {dir_path}"
                    })
            
            # Issue 4: Logs com erros
            log_files = list(base_path.glob("*.log"))
            for log_file in log_files:
                try:
                    with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    if 'ERROR' in content or 'Exception' in content:
                        issues.append({
                            'type': 'log_errors',
                            'severity': 'HIGH',
                            'description': f"Erros detectados em {log_file.name}",
                            'solution': "Investigar e corrigir erros espec√≠ficos"
                        })
                except:
                    pass
            
            self.logger.info(f"üîç Total de problemas detectados: {len(issues)}")
            for issue in issues:
                self.logger.warning(f"‚ö†Ô∏è {issue['severity']}: {issue['description']}")
            
            return issues
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na detec√ß√£o de problemas: {e}")
            return [{'type': 'detection_error', 'description': str(e)}]
    
    def _generate_recommendations(self) -> List[str]:
        """Gera recomenda√ß√µes baseadas na an√°lise"""
        recommendations = [
            "Implementar processamento real de arquivos MQL4 (n√£o simula√ß√£o)",
            "Adicionar valida√ß√£o rigorosa de sintaxe MQL4",
            "Implementar detec√ß√£o autom√°tica de estrat√©gias de trading",
            "Criar sistema de classifica√ß√£o FTMO mais preciso",
            "Adicionar gera√ß√£o de snippets de c√≥digo reutiliz√°veis",
            "Implementar sistema de backup autom√°tico",
            "Criar dashboard de monitoramento em tempo real",
            "Adicionar testes automatizados de qualidade",
            "Implementar sistema de versionamento de arquivos",
            "Criar API para integra√ß√£o com outras ferramentas"
        ]
        
        self.logger.info("üí° Recomenda√ß√µes geradas:")
        for i, rec in enumerate(recommendations, 1):
            self.logger.info(f"  {i}. {rec}")
        
        return recommendations
    
    def _apply_auto_fixes(self, base_path: Path) -> List[str]:
        """Aplica corre√ß√µes autom√°ticas"""
        fixes_applied = []
        
        try:
            # Fix 1: Criar diret√≥rios obrigat√≥rios
            required_dirs = [
                "CODIGO_FONTE_LIBRARY/MQL4_Source/EAs/Scalping",
                "CODIGO_FONTE_LIBRARY/MQL4_Source/EAs/Grid_Martingale",
                "CODIGO_FONTE_LIBRARY/MQL4_Source/EAs/Trend_Following",
                "CODIGO_FONTE_LIBRARY/MQL4_Source/Indicators/SMC_ICT",
                "CODIGO_FONTE_LIBRARY/MQL4_Source/Indicators/Volume",
                "CODIGO_FONTE_LIBRARY/MQL4_Source/Scripts/Utilities",
                "Reports",
                "Metadata",
                "Snippets"
            ]
            
            for dir_path in required_dirs:
                full_path = base_path / dir_path
                if not full_path.exists():
                    full_path.mkdir(parents=True, exist_ok=True)
                    fixes_applied.append(f"Criado diret√≥rio: {dir_path}")
                    self.logger.info(f"‚úÖ Criado: {dir_path}")
            
            # Fix 2: Criar arquivo de configura√ß√£o
            config_path = base_path / "config_sistema.json"
            if not config_path.exists():
                config = {
                    "version": "6.0",
                    "batch_size": 100,
                    "max_threads": 4,
                    "timeout_per_file": 60,
                    "enable_real_processing": True,
                    "enable_ftmo_validation": True,
                    "enable_auto_backup": True
                }
                
                with open(config_path, 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                
                fixes_applied.append("Criado arquivo de configura√ß√£o")
                self.logger.info("‚úÖ Arquivo de configura√ß√£o criado")
            
            # Fix 3: Limpar logs antigos
            log_files = list(base_path.glob("*.log"))
            if len(log_files) > 5:
                # Manter apenas os 5 logs mais recentes
                log_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
                for old_log in log_files[5:]:
                    old_log.unlink()
                    fixes_applied.append(f"Removido log antigo: {old_log.name}")
            
            self.logger.info(f"üîß Total de corre√ß√µes aplicadas: {len(fixes_applied)}")
            
            return fixes_applied
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao aplicar corre√ß√µes: {e}")
            return [f"Erro ao aplicar corre√ß√µes: {e}"]

def main():
    """Fun√ß√£o principal do diagn√≥stico"""
    base_path = r"C:\Users\Admin\Documents\EA_SCALPER_XAUUSD"
    
    print("üîç SISTEMA DE DIAGN√ìSTICO AVAN√áADO")
    print("=" * 50)
    
    diagnostics = SystemDiagnostics()
    results = diagnostics.run_full_diagnostic(base_path)
    
    # Salvar relat√≥rio de diagn√≥stico
    report_path = Path(base_path) / "Reports" / f"diagnostico_completo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    report_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÑ Relat√≥rio de diagn√≥stico salvo em: {report_path}")
    print("\nüéØ RESUMO DO DIAGN√ìSTICO:")
    print(f"  ‚Ä¢ Problemas detectados: {len(results.get('issues_detected', []))}")
    print(f"  ‚Ä¢ Corre√ß√µes aplicadas: {len(results.get('auto_fixes_applied', []))}")
    print(f"  ‚Ä¢ Recomenda√ß√µes geradas: {len(results.get('recommendations', []))}")
    
    return results

if __name__ == "__main__":
    main()