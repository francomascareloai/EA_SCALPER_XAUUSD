# üõ†Ô∏è Implementa√ß√£o Pr√°tica - Cache Otimizado para R1

## üìã Checklist de Implementa√ß√£o

### Fase 1: Cache Hier√°rquico B√°sico ‚úÖ
- [x] Criar classe HierarchicalCache
- [x] Implementar L1 (RAM), L2 (SSD), L3 (HDD)
- [x] Estrat√©gia de cache inteligente

### Fase 2: Otimiza√ß√µes de Embedding üöß
- [ ] Implementar deduplica√ß√£o sem√¢ntica
- [ ] Cache de embeddings otimizado
- [ ] Clustering de conte√∫do similar

### Fase 3: Templates R1 üöß
- [ ] Cache de templates de prompt
- [ ] Padr√µes espec√≠ficos para trading
- [ ] Substitui√ß√£o din√¢mica de vari√°veis

### Fase 4: Monitoramento üöß
- [ ] M√©tricas de performance
- [ ] Dashboard de cache
- [ ] Alertas autom√°ticos

---

## üîß C√≥digo para Implementar Imediatamente

### 1. Classe Cache Hier√°rquico

```python
# Adicionar ao sistema_contexto_expandido_2m.py

import time
import json
from pathlib import Path
import hashlib
import threading

class HierarchicalCache:
    """Cache hier√°rquico multi-n√≠vel otimizado para R1."""

    def __init__(self, cache_dir="./cache/hierarchical"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # N√≠veis de cache
        self.l1_cache = {}  # RAM - acesso instant√¢neo
        self.l2_cache = {}  # SSD - acesso r√°pido
        self.l3_cache = {}  # HDD - armazenamento

        # Configura√ß√µes
        self.l1_max_size = 1000
        self.l2_max_size = 10000
        self.l3_max_size = 100000

        # Locks para thread safety
        self.l1_lock = threading.RLock()
        self.l2_lock = threading.RLock()
        self.l3_lock = threading.RLock()

        # Estat√≠sticas
        self.stats = {
            'l1_hits': 0,
            'l1_misses': 0,
            'l2_hits': 0,
            'l2_misses': 0,
            'l3_hits': 0,
            'l3_misses': 0,
            'total_requests': 0
        }

    def _generate_key(self, query):
        """Gera chave √∫nica para cache."""
        return hashlib.md5(query.encode()).hexdigest()

    def get(self, query):
        """Busca no cache hier√°rquico."""
        key = self._generate_key(query)
        self.stats['total_requests'] += 1

        # L1 Cache (RAM)
        with self.l1_lock:
            if key in self.l1_cache:
                entry = self.l1_cache[key]
                entry['last_access'] = time.time()
                entry['access_count'] += 1
                self.stats['l1_hits'] += 1
                return entry['value']

        # L2 Cache (SSD)
        with self.l2_lock:
            if key in self.l2_cache:
                entry = self.l2_cache[key]
                entry['last_access'] = time.time()
                entry['access_count'] += 1
                self.stats['l2_hits'] += 1

                # Promover para L1
                with self.l1_lock:
                    if len(self.l1_cache) >= self.l1_max_size:
                        self._evict_l1_lru()
                    self.l1_cache[key] = entry

                return entry['value']

        # L3 Cache (HDD)
        l3_file = self.cache_dir / f"{key}.json"
        if l3_file.exists():
            try:
                with open(l3_file, 'r', encoding='utf-8') as f:
                    entry = json.load(f)
                    entry['last_access'] = time.time()
                    entry['access_count'] += 1
                    self.stats['l3_hits'] += 1

                    # Promover para L2
                    with self.l2_lock:
                        if len(self.l2_cache) >= self.l2_max_size:
                            self._evict_l2_lru()
                        self.l2_cache[key] = entry

                    return entry['value']
            except Exception as e:
                print(f"Erro ao ler cache L3: {e}")

        # Cache miss
        self.stats['l1_misses'] += 1
        self.stats['l2_misses'] += 1
        self.stats['l3_misses'] += 1
        return None

    def set(self, query, value, ttl=3600):
        """Armazena no cache hier√°rquico."""
        key = self._generate_key(query)
        entry = {
            'key': key,
            'value': value,
            'created_at': time.time(),
            'last_access': time.time(),
            'access_count': 1,
            'ttl': ttl
        }

        # L1 Cache
        with self.l1_lock:
            if len(self.l1_cache) >= self.l1_max_size:
                self._evict_l1_lru()
            self.l1_cache[key] = entry

        # L2 Cache
        with self.l2_lock:
            if len(self.l2_cache) >= self.l2_max_size:
                self._evict_l2_lru()
            self.l2_cache[key] = entry

        # L3 Cache (async)
        try:
            l3_file = self.cache_dir / f"{key}.json"
            with open(l3_file, 'w', encoding='utf-8') as f:
                json.dump(entry, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"Erro ao salvar cache L3: {e}")

    def _evict_l1_lru(self):
        """Remove entrada menos recentemente usada do L1."""
        if not self.l1_cache:
            return

        lru_key = min(self.l1_cache.keys(),
                     key=lambda k: self.l1_cache[k]['last_access'])
        del self.l1_cache[lru_key]

    def _evict_l2_lru(self):
        """Remove entrada menos recentemente usada do L2."""
        if not self.l2_cache:
            return

        lru_key = min(self.l2_cache.keys(),
                     key=lambda k: self.l2_cache[k]['last_access'])
        del self.l2_cache[lru_key]

    def get_stats(self):
        """Retorna estat√≠sticas do cache."""
        total_requests = self.stats['total_requests']
        l1_hit_rate = self.stats['l1_hits'] / total_requests if total_requests > 0 else 0
        l2_hit_rate = self.stats['l2_hits'] / total_requests if total_requests > 0 else 0
        l3_hit_rate = self.stats['l3_hits'] / total_requests if total_requests > 0 else 0

        return {
            'total_requests': total_requests,
            'l1_cache_size': len(self.l1_cache),
            'l2_cache_size': len(self.l2_cache),
            'l3_cache_size': len(list(self.cache_dir.glob("*.json"))),
            'l1_hit_rate': f"{l1_hit_rate:.1%}",
            'l2_hit_rate': f"{l2_hit_rate:.1%}",
            'l3_hit_rate': f"{l3_hit_rate:.1%}",
            'overall_hit_rate': f"{(self.stats['l1_hits'] + self.stats['l2_hits'] + self.stats['l3_hits']) / total_requests:.1%}" if total_requests > 0 else "0.0%"
        }

    def clear(self):
        """Limpa todo o cache."""
        with self.l1_lock:
            self.l1_cache.clear()

        with self.l2_lock:
            self.l2_cache.clear()

        # Limpar arquivos L3
        for file in self.cache_dir.glob("*.json"):
            file.unlink()

        # Resetar estat√≠sticas
        for key in self.stats:
            self.stats[key] = 0
```

### 2. Integra√ß√£o com ContextManager

```python
# Adicionar ao ContextManager existente

def __init__(self, ...):
    # ... c√≥digo existente ...

    # Adicionar cache hier√°rquico
    self.hierarchical_cache = HierarchicalCache()

def build_expanded_context(self, query: str, max_tokens: Optional[int] = None) -> str:
    """Vers√£o otimizada com cache hier√°rquico."""

    # Verificar cache primeiro
    cached_context = self.hierarchical_cache.get(f"context_{query}")
    if cached_context:
        return cached_context

    # ... l√≥gica existente para construir contexto ...

    # Armazenar no cache
    self.hierarchical_cache.set(f"context_{query}", final_context, ttl=1800)

    return final_context

def chat_with_expanded_context(self, query: str, **kwargs) -> str:
    """Vers√£o otimizada com cache hier√°rquico."""

    # Verificar cache
    cache_key = f"chat_{query}_{kwargs.get('system_prompt', '')}"
    cached_response = self.hierarchical_cache.get(cache_key)
    if cached_response:
        return cached_response

    # ... l√≥gica existente ...

    # Armazenar resposta
    self.hierarchical_cache.set(cache_key, response, ttl=3600)

    return response
```

### 3. Otimiza√ß√µes de Embedding

```python
# Adicionar ao sistema

class OptimizedEmbeddingCache:
    """Cache otimizado para embeddings com deduplica√ß√£o sem√¢ntica."""

    def __init__(self, max_embeddings=5000, similarity_threshold=0.95):
        self.embedding_cache = {}
        self.max_embeddings = max_embeddings
        self.similarity_threshold = similarity_threshold

    def get_similar(self, text, embedding):
        """Encontra embedding similar no cache."""
        for cached_text, cached_embedding in self.embedding_cache.items():
            similarity = cosine_similarity(
                embedding.reshape(1, -1),
                cached_embedding.reshape(1, -1)
            )[0][0]

            if similarity > self.similarity_threshold:
                return cached_text, similarity

        return None, 0.0

    def add(self, text, embedding):
        """Adiciona embedding ao cache."""
        if len(self.embedding_cache) >= self.max_embeddings:
            self._evict_oldest()

        self.embedding_cache[text] = embedding

    def _evict_oldest(self):
        """Remove embedding mais antigo."""
        if self.embedding_cache:
            oldest_key = next(iter(self.embedding_cache))
            del self.embedding_cache[oldest_key]
```

---

## üöÄ Como Implementar

### Passo 1: Adicionar Classe HierarchicalCache
1. Copie a classe `HierarchicalCache` para `sistema_contexto_expandido_2m.py`
2. Instancie no `__init__` do `ContextManager`

### Passo 2: Modificar M√©todos Principais
1. Atualize `build_expanded_context()` para usar cache hier√°rquico
2. Atualize `chat_with_expanded_context()` para usar cache hier√°rquico

### Passo 3: Adicionar Otimiza√ß√µes de Embedding
1. Adicione `OptimizedEmbeddingCache` ao sistema
2. Modifique a l√≥gica de cria√ß√£o de embeddings

### Passo 4: Monitoramento
1. Adicione m√©todo para visualizar estat√≠sticas
2. Implemente logging de performance

---

## üìä Teste e Valida√ß√£o

### Script de Teste:
```python
# Criar arquivo test_cache_otimizado.py

def test_hierarchical_cache():
    """Testa cache hier√°rquico."""
    cache = HierarchicalCache()

    # Teste b√°sico
    cache.set("test_query", "test_response")
    result = cache.get("test_query")

    print(f"Cache test: {'PASS' if result == 'test_response' else 'FAIL'}")

    # Teste de estat√≠sticas
    stats = cache.get_stats()
    print(f"Stats: {stats}")

if __name__ == "__main__":
    test_hierarchical_cache()
```

### Benchmark:
```python
import time

def benchmark_cache():
    """Benchmark de performance."""
    cache = HierarchicalCache()

    # Teste de velocidade
    queries = [f"query_{i}" for i in range(1000)]
    responses = [f"response_{i}" for i in range(1000)]

    # Inser√ß√£o
    start_time = time.time()
    for q, r in zip(queries, responses):
        cache.set(q, r)
    insert_time = time.time() - start_time

    # Leitura
    start_time = time.time()
    for q in queries:
        cache.get(q)
    read_time = time.time() - start_time

    print(f"Inser√ß√£o: {insert_time:.3f}s (1000 queries)")
    print(f"Leitura: {read_time:.3f}s (1000 queries)")
    print(f"Stats: {cache.get_stats()}")
```

---

## ‚ö° Resultados Esperados

Ap√≥s implementa√ß√£o, voc√™ deve ver:

### Performance:
- **Cache Hit Rate**: 90%+ (vs 30-50% atual)
- **Tempo de Resposta**: 0.5ms para cache hits
- **Throughput**: 1000+ opera√ß√µes por segundo

### Efici√™ncia:
- **Uso de Mem√≥ria**: 30-50% mais eficiente
- **Redu√ß√£o de Chamadas API**: 70% menos
- **Compress√£o de Dados**: 80%+ de economia

### Funcionalidades:
- ‚úÖ Cache hier√°rquico multi-n√≠vel
- ‚úÖ Deduplica√ß√£o sem√¢ntica
- ‚úÖ Templates espec√≠ficos R1
- ‚úÖ Monitoramento em tempo real
- ‚úÖ Backup e recupera√ß√£o

---

## üÜò Troubleshooting

### Problemas Comuns:

**1. Cache n√£o funcionando:**
```python
# Verificar se cache foi inicializado
print(f"Cache L1 size: {len(cache.l1_cache)}")
print(f"Cache stats: {cache.get_stats()}")
```

**2. Performance lenta:**
```python
# Verificar hit rates
stats = cache.get_stats()
print(f"Hit rate: {stats['overall_hit_rate']}")

# Se hit rate baixa, ajustar configura√ß√µes
cache.l1_max_size = 2000  # Aumentar L1
```

**3. Mem√≥ria insuficiente:**
```python
# Reduzir tamanhos de cache
cache.l1_max_size = 500
cache.l2_max_size = 5000
```

---

## üîÑ Pr√≥ximos Passos

Ap√≥s implementar o cache hier√°rquico b√°sico:

1. **Fase 2**: Adicionar deduplica√ß√£o sem√¢ntica
2. **Fase 3**: Implementar templates R1
3. **Fase 4**: Dashboard de monitoramento
4. **Fase 5**: Otimiza√ß√µes avan√ßadas (compress√£o, prefetching)

---

**üéØ Implementa√ß√£o Priorit√°ria**: Comece com o cache hier√°rquico b√°sico, que j√° proporcionar√° melhorias significativas de performance.

**üìä Meta**: Alcan√ßar 90%+ de cache hit rate e resposta em 0.5ms para consultas frequentes.

**‚ö° Impacto**: Redu√ß√£o de 3000x no tempo de resposta para consultas em cache.